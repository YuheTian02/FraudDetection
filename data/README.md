# Data Directory

This directory contains the datasets used in the fraud detection analysis.

## Structure

### Raw Data (`raw/`)
Contains the original, unprocessed data files:
- **`fraud_detection_dataset_part1.xlsx`**: Part 1 dataset for anomaly detection analysis
  - Contains application data with fraud indicators
  - Used for time-series analysis and anomaly detection
  
- **`fraud_detection_dataset_part2.xlsx`**: Part 2 dataset for fraud detection model development
  - Contains features including FraudKiller attributes
  - Used for building and comparing ML models

### Cleaned Data (`cleaned/`)
Contains processed and cleaned datasets (automatically generated by the notebook):
- **`fraud_detection_cleaned.xlsx`**: Part 1 cleaned dataset
  - Missing values imputed using KNN
  - Data quality issues fixed (e.g., transaction date corrections)
  - Ready for analysis
  
- **`fraud_detection_processed_part2.csv`**: Part 2 processed dataset
  - Feature engineering completed (encoding, scaling, imputation)
  - Ready for machine learning model training

## Data Processing

The notebook automatically:
1. Loads raw data from `data/raw/`
2. Performs cleaning and preprocessing
3. Saves processed datasets to `data/cleaned/`

You can reload the cleaned datasets directly to skip preprocessing steps if needed.

## File Management

- **Raw data**: Manually uploaded and tracked in version control
- **Cleaned data**: Generated automatically, can be regenerated from raw data
- If data files are large or sensitive, consider:
  - Using Git LFS for large files
  - Adding to `.gitignore` if they shouldn't be tracked
  - Using environment variables for sensitive paths

